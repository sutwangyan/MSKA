task: S2T
device: cuda
do_translation: True
do_recognition: True
data:
  train_label_path: data/Phoenix-2014T/Phoenix-2014T.train
  dev_label_path: data/Phoenix-2014T/Phoenix-2014T.dev
  test_label_path: data/Phoenix-2014T/Phoenix-2014T.test
  max_length: 300
  input_streams: keypoint
  level: word  #word or char
  txt_lowercase: true
  max_sent_length: 400
  dataset_name: Phoenix-2014T

testing:
  recognition:
    beam_size: 5
  translation:
    length_penalty: 1
    max_length: 100
    num_beams: 5
gloss:
  gloss2id_file: data/Phoenix-2014T/gloss2ids.pkl
training:
  wandb: disabled # online or disabled
  model_dir: /outputs/phoenix-2014T_SLT
  validation:
    recognition:
      beam_size: 1
    translation:
      length_penalty: 1
      max_length: 100
      num_beams: 5
  optimization:
    optimizer: Adam
    learning_rate:
      default: 1.0e-05
      mapper: 1.0e-3
      translation: 1.0e-05
    weight_decay: 0.001
    betas:
      - 0.9
      - 0.998
    scheduler: cosineannealing
    t_max: 40
model:
  RecognitionNetwork:
    pretrained_path: pretrained_models/Phoenix-2014T_SLR/best.pth
    input_type: keypoint
    DSTA-Net:
      net: [[64, 64, 16, 7, 2], [64, 64, 16, 3, 1],
            [64, 128, 32, 3, 1], [128, 128, 32, 3, 1],
            [128, 256, 64, 3, 2], [256, 256, 64, 3, 1],
            [256, 256, 64, 3, 1], [256, 256, 64, 3, 1],]
      body: [0,1,3,5,7,9,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,2,4,6,8,10,112,113,
             114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,23,26,29,33,36,39,41,43,46,48,
             53,56,59,62,65,68,71,72,73,74,75,76,77,79,80,81]
      left: [0,1,3,5,7,9,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111]
      right: [0,2,4,6,8,10,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132]
      face: [23,26,29,33,36,39,41,43,46,48,53,56,59,62,65,68,71,72,73,74,75,76,77,79,80,81]
      mouth: [71,72,73,74,75,76,77,79,80,81]
    GlossTokenizer:
      gloss2id_file: data/Phoenix-2014T/gloss2ids.pkl
    body_visual_head:
      input_size: 256
      hidden_size: 512
      ff_size: 2048
      pe: True
      ff_kernelsize:
        - 3
        - 3
    fuse_visual_head:
      input_size: 1024
      hidden_size: 512
      ff_size: 2048
      pe: True
      ff_kernelsize:
        - 3
        - 3
    left_visual_head:
      input_size: 512
      hidden_size: 512
      ff_size: 2048
      pe: True
      ff_kernelsize:
        - 3
        - 3
    right_visual_head:
      input_size: 512
      hidden_size: 512
      ff_size: 2048
      pe: True
      ff_kernelsize:
        - 3
        - 3
  TranslationNetwork:
    GlossEmbedding:
      freeze: false
      gloss2embed_file: pretrained_models/mBart_de/gloss_embeddings.bin
    GlossTokenizer:
      gloss2id_file: pretrained_models/mBart_de/gloss2ids.pkl
      src_lang: de_DGS
    TextTokenizer:
      pretrained_model_name_or_path: pretrained_models/mBart_de
      pruneids_file: pretrained_models/mBart_de/map_ids.pkl
      tgt_lang: de_DE
    load_ckpt: pretrained_models/phoenix-2014T_g2t/best.ckpt
    pretrained_model_name_or_path: pretrained_models/mBart_de
    overwrite_cfg:
      attention_dropout: 0.1
      dropout: 0.3
  VLMapper:
    in_features: 512
    multistream_fuse: empty